<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Homework 2 Writeup</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
</head>
<body>
<div id="header">
<h1 class="title">Homework 2 Writeup</h1>
</div>
<h1 id="objective-of-the-work" class="unnumbered">Objective of the work</h1>
<p>The main goal of the work is to implement visual recognition of different environments based on feature descriptors. There are 15 labels of images and there are 100 images from each category in training, as well as test set.</p>
<div class="figure">
<img src="categories.jpg" alt="Exemplary images from the dataset " width="377" />
<p class="caption">Exemplary images from the dataset <span class="citation"></span><span data-label="fig:dataset"></span></p>
</div>
<p>Process of performing visual recognition of depicted environments could be seen as a sequence of following processes:</p>
<div class="figure">
<img src="flow_scene_recognition.jpg" alt="Flow chart of scene recognition scheme" width="264" />
<p class="caption">Flow chart of scene recognition scheme<span data-label="fig:flowchart_scene_recognition"></span></p>
</div>
<h1 id="building-vocabulary-by-k-means-clustering" class="unnumbered">Building vocabulary by k-means clustering</h1>
<h2 id="feature-extraction" class="unnumbered">Feature extraction</h2>
<p>In the exercise I used two feature extractors: Histogram of oriented gradients (HOG) and Scale-invariant feature transform (SIFT) algorithm.<br />
HOG algorithm breaks image to cells, compute histogram of oriented gradients in the cells, normalize output across the block formed from cells and add up all gradients. I used <code>cv2.HOGDescriptor()</code> function, which returns concatenated list for all feature, which has to be re-scaled to size <span class="math inline">(<em>n</em><em>u</em><em>m</em>_<em>f</em><em>e</em><em>a</em><em>t</em><em>u</em><em>r</em><em>e</em><em>s</em> × 36)</span>.<br />
SIFT algorithm uses scale-space extrema detection with gaussian kernel ans keypoint localization to find relevant features. I used <code>cv2.xfeatures2d.SIFT_create()</code> which returns list of features of size <span class="math inline">(<em>n</em><em>u</em><em>m</em>_<em>f</em><em>a</em><em>t</em><em>u</em><em>r</em><em>e</em><em>s</em> × 36)</span>. Code which performs feature extraction is shown below:</p>
<div class="sourceCode" language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> feature_extraction(img, feature):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    This function computes defined feature (HoG, SIFT) descriptors of the target image.</span>

<span class="co">    :param img: a height x width x channels matrix,</span>
<span class="co">    :param feature: name of image feature representation.</span>

<span class="co">    :return: a N x feature_size matrix.</span>
<span class="co">    &quot;&quot;&quot;</span>

    <span class="cf">if</span> feature <span class="op">==</span> <span class="st">&#39;HoG&#39;</span>:

        win_size <span class="op">=</span> (<span class="dv">32</span>, <span class="dv">32</span>)
        block_size <span class="op">=</span> (<span class="dv">32</span>, <span class="dv">32</span>)
        block_stride <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">16</span>)
        cell_size <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">16</span>)

        nbins <span class="op">=</span> <span class="dv">9</span>
        deriv_aperture <span class="op">=</span> <span class="dv">1</span>
        win_sigma <span class="op">=</span> <span class="dv">4</span>
        histogram_norm_type <span class="op">=</span> <span class="dv">0</span>
        l2_hys_threshold <span class="op">=</span> <span class="fl">2.0000000000000001e-01</span>
        gamma_correction <span class="op">=</span> <span class="dv">0</span>
        nlevels <span class="op">=</span> <span class="dv">64</span>

        <span class="co"># Your code here. You should also change the return value.</span>

        <span class="co"># sample visualizing</span>
        <span class="co"># cv2.imshow(&#39;img&#39;, img)</span>

        gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)


        hog <span class="op">=</span> cv2.HOGDescriptor(win_size,
                                block_size,
                                block_stride,
                                cell_size,
                                nbins,
                                deriv_aperture,
                                win_sigma,
                                histogram_norm_type,
                                l2_hys_threshold,
                                gamma_correction,
                                nlevels)

        hist <span class="op">=</span> hog.compute(gray)
        hist_resized <span class="op">=</span> np.resize(hist, (<span class="bu">int</span>(<span class="bu">len</span>(hist)<span class="op">/</span><span class="dv">36</span>), <span class="dv">36</span>))
        hist_resized
        <span class="cf">return</span> hist_resized

    <span class="cf">elif</span> feature <span class="op">==</span> <span class="st">&#39;SIFT&#39;</span>:

        gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        sift <span class="op">=</span> cv2.xfeatures2d.SIFT_create()
        kp, des <span class="op">=</span> sift.detectAndCompute(gray, <span class="va">None</span>)

        <span class="cf">return</span> des</code></pre></div>
<h2 id="learning-visual-vocabulary-using-k-means-clustering" class="unnumbered">Learning visual vocabulary using K-means clustering</h2>
<p>After feature extraction there are multiple features for every image. To build “viusal vocabulary” from “visual words”. “Visual vocabulary” is a set of unique features derived from the training set. With the assumptions that there are regions where density of real features are higher, we could find those regions by K-means clustering.</p>
<p>Find maximum (max_feat) and minimum value (min_feat)<br />
of each feature<br />
Randomly assign centroids in the range max_feat, min_feat<br />
</p>
<h3 id="principle-component-analysispca-for-vocabulary" class="unnumbered">Principle component analysis(PCA) for vocabulary</h3>
<p>Feature space for HOG algorithm equals 36 and for SIFT algorithm 128. Since it is impossible to visualize in a meaningful way such high dimensional data, we could use PCA for such task. PCA could be also perform as a preprocessing step to reduce the dimensionality of the data and to decrease the variance of our model.</p>
<p><span>.5</span> <img src="PCA_sift_2d.png" title="fig:" alt="First 3 Principal Components for SIFT and HOG algorithm" /></p>
<p><span>.5</span> <img src="PCA_HOG_2d.png" title="fig:" alt="First 3 Principal Components for SIFT and HOG algorithm" /></p>
<p><span>.5</span> <img src="PCA_sift_3d.png" title="fig:" alt="First 3 Principal Components for SIFT and HOG algorithm" /></p>
<p><span>.5</span> <img src="PCA_HOG_3d.png" title="fig:" alt="First 3 Principal Components for SIFT and HOG algorithm" /></p>
<p>Function which performs PC extraction is shown below:</p>
<div class="sourceCode" language="Python"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> get_features_from_pca(feat_num, feature):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    This function loads &#39;vocab_sift.npy&#39; or &#39;vocab_hog.npg&#39; file and</span>
<span class="co">    returns dimension-reduced vocab into 2D or 3D.</span>

<span class="co">    :param feat_num: 2 when we want 2D plot, 3 when we want 3D plot</span>
<span class="co">    :param feature: &#39;Hog&#39; or &#39;SIFT&#39;</span>

<span class="co">    :return: an N x feat_num matrix</span>
<span class="co">    &quot;&quot;&quot;</span>

    <span class="cf">if</span> feature <span class="op">==</span> <span class="st">&#39;HoG&#39;</span>:
        vocab <span class="op">=</span> np.load(<span class="st">&#39;vocab_hog.npy&#39;</span>)
    <span class="cf">elif</span> feature <span class="op">==</span> <span class="st">&#39;SIFT&#39;</span>:
        vocab <span class="op">=</span> np.load(<span class="st">&#39;vocab_sift.npy&#39;</span>)

    <span class="kw">def</span> _get_PCA_vectors(feat_num, vocab):

        mean <span class="op">=</span> vocab.mean(axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>)
        vocab_normalized <span class="op">=</span> vocab <span class="op">-</span> np.multiply(np.ones([vocab.shape[<span class="dv">0</span>], 
            mean.shape[<span class="dv">0</span>]]), mean)
        <span class="co">#TEST: mean unit test</span>
        <span class="co">#mean = vocab_normalized.mean(axis=0, keepdims=True)</span>

        cov_matrix <span class="op">=</span> np.cov(np.transpose(vocab_normalized))
        sigma, V <span class="op">=</span> np.linalg.eig(cov_matrix)
        order_sigma <span class="op">=</span> np.argsort(sigma)

        PCA_vectors <span class="op">=</span> []
        i <span class="op">=</span> <span class="dv">1</span>
        <span class="cf">for</span> f <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(order_sigma)):
            eigen_vector <span class="op">=</span> V[:, order_sigma[i]]
            <span class="cf">if</span> <span class="bu">all</span>(<span class="va">True</span> <span class="cf">for</span> _ <span class="kw">in</span> np.isreal(eigen_vector)):
                PCA_vectors.append(np.real(eigen_vector))
                i <span class="op">+=</span> <span class="dv">1</span>
            <span class="cf">if</span> <span class="bu">len</span>(PCA_vectors) <span class="op">==</span> feat_num:
                <span class="cf">break</span>

        <span class="cf">return</span> np.array(PCA_vectors)

    <span class="co">#MAIN</span>
    PCA_vectors <span class="op">=</span> _get_PCA_vectors(feat_num, vocab)

    d <span class="op">=</span> np.dot(vocab, np.transpose(PCA_vectors))

    <span class="cf">return</span> np.dot(vocab, np.transpose(PCA_vectors))</code></pre></div>
<h1 id="representing-images-from-training-set-by-frequencies-of-visual-words" class="unnumbered">Representing images from training set by frequencies of “visual words”</h1>
<p>I implemented 2 approaches (Bag of words and Spatial Pyramid) to combine features obtain from every image into meaningful low-dimensional input into SVM classifier.</p>
<h2 id="bag-of-words-representation-of-scenes" class="unnumbered">Bag of words representation of scenes</h2>
<p>Bag of words implementation involve representing features of every image by code vectors of the “visual vocabulary” and combining those codevectors into normalized histogram of occurrences. Bag of words implementation doesn’t contain any information about spatial location and proximity between features.</p>
<h2 id="spatial-pyramid-representation" class="unnumbered">Spatial pyramid representation</h2>
<p>Spatial pyramid representation is a more complex form than Bag of words, which involves also information about spatial location of features obtaining for every image. In this approach histogram of features is obtained by weighted sum of histograms for multiple levels of images. Each level of images involve <span class="math inline">4<sup><em>l</em></sup></span> equal sized subimages of the original image.</p>
<h1 id="multi-class-svm" class="unnumbered">Multi-class SVM</h1>
<p>Having representation of images from training set by frequencies of “visual words” the next step is to learn SVM classifier which would be capable to recognize environments from <span class="citation"></span>. SVM classifier is a binary classifier, so to obtain the classification task between 15 classes in the model I trained 15 “one vs. all”. For every image there are 15 probabilities that the class is the choosen one. In the training set for every image is chosen class which has the highest probability obtained by “one vs. all” classifier for this class. Code which executes “one vs. all” classificator is shown below:</p>
<div class="sourceCode" language="Python"><pre class="sourceCode python"><code class="sourceCode python">    categories <span class="op">=</span> np.unique(train_labels)

    categories_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(np.arange(<span class="dv">15</span>), categories))

    all_predicted_proba <span class="op">=</span> np.empty([<span class="dv">1500</span>,<span class="dv">1</span>])

    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(categories)):
        one_vs_all_labels <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> n <span class="op">==</span> categories[c] 
            <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">for</span> n <span class="kw">in</span> train_labels]
        clf <span class="op">=</span> svm.SVC(probability<span class="op">=</span><span class="va">True</span>, gamma<span class="op">=</span><span class="st">&#39;auto&#39;</span>, 
            kernel<span class="op">=</span>kernel_type)
        clf.fit(train_image_feats, one_vs_all_labels)
        predicted_proba <span class="op">=</span> clf.predict_proba(test_image_feats)
        predicted_proba <span class="op">=</span> predicted_proba[:,<span class="dv">1</span>].
            reshape((<span class="bu">len</span>(predicted_proba[:,<span class="dv">1</span>]),<span class="dv">1</span>))
        all_predicted_proba <span class="op">=</span> np.hstack((all_predicted_proba,
                                        predicted_proba))

    all_predicted_proba <span class="op">=</span> all_predicted_proba[:,<span class="dv">1</span>:]

    max_proba <span class="op">=</span> np.argmax(all_predicted_proba, axis<span class="op">=</span><span class="dv">1</span>)

    out_labels <span class="op">=</span> np.array([categories_dict[x] 
        <span class="cf">for</span> x <span class="kw">in</span> max_proba])

    <span class="cf">return</span> out_labels</code></pre></div>
<h2 id="the-kernel-trick" class="unnumbered">The kernel trick</h2>
<p>SVM classification could be obtain by solving Dual problem: <br /><span class="math display">$$max L_{D}(a_{i}) = \Sigma^{l}_{i=1} - \frac{1}{2}\Sigma^{l}_{i=1}a_{i}a_{j}y_{i}y_{j}({\mathbf{x_{i}}}\cdot{\mathbf{x_{j}}})s.t.$$</span><br /> <span class="math inline"><em>Σ</em><sub><em>i</em> = 1</sub><sup><em>l</em></sup><em>a</em><sub><em>i</em></sub><em>y</em><sub><em>i</em></sub> = 0</span> &amp; <span class="math inline"><em>a</em><sub><em>i</em></sub> &gt; =0</span> We obtain coefficients <span class="math inline"><em>a</em></span> by nonlinear optimization and in the training process to obtain the classification we only have to compute <span class="math inline">(<strong>x</strong><sub><strong>i</strong></sub> ⋅ <strong>x</strong><sub><strong>j</strong></sub>)</span>, between all training examples for which <span class="math inline"><em>a</em><sub><em>i</em></sub> = 0</span> and new point (<span class="math inline"><em>a</em><sub><em>i</em></sub></span> is non-zero only for support vectors). This term could be wraped into to different kernel functions <span class="math inline"><em>K</em>(<strong>x</strong><sub><strong>i</strong></sub> ⋅ <strong>x</strong><sub><strong>j</strong></sub>)</span> to imitate feature expansion to get non-linear SVM decision boundary.<br />
We could use radial basis function (RBF) kernel, which we get by computing: <br /><span class="math display"><em>K</em><sub><em>R</em><em>B</em><em>F</em></sub>(<strong>x</strong><sub><strong>i</strong></sub> ⋅ <strong>x</strong><sub><strong>j</strong></sub>)=<em>e</em><sup>−<em>γ</em>||<strong>x</strong><sub><strong>i</strong></sub> − <strong>x</strong><sub><strong>j</strong></sub>||<sup>2</sup></sup></span><br /> When parameter <span class="math inline"><em>γ</em></span> is higher we place lower impact on the difference between training points and new observation, so the “area of influence of support vectors is lower” and model is prone to overfitting.</p>
<h1 id="accuracy-of-the-model" class="unnumbered">Accuracy of the model</h1>
<h2 id="comparsion-of-sift-and-hog-performance" class="unnumbered">Comparsion of SIFT and HOG performance</h2>
<p>In the model I used two feature exctractors SIFT and HOG.</p>
<table>
<thead>
<tr class="header">
<th align="left">Feature extractor</th>
<th align="left">Kernel</th>
<th align="left">Representation</th>
<th align="left">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left"><span class="math inline">43.0%</span></td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left"><span class="math inline">41.9%</span></td>
</tr>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left"><span class="math inline">46.4%</span></td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left"><span class="math inline">46.3%</span></td>
</tr>
</tbody>
</table>
<p>As shown in table 1 SIFT features has <span class="math inline">1.1%</span> higher accuracy on the used dataset than HOG using Bag of words and <span class="math inline">0.1%</span> higher with use Spatial pyramid. The reason could be fact that, as mentioned above SIFT features include information about spatial location of the feature. Though, in the model especially with use of Spatial pyramid increase in the accuracy is not siginificant and depending on the task Bag of words could be better choice since computational complexity for this algorithm is significantly lower than for Spatial Pyramid.</p>
<h2 id="comparsion-of-linear-and-rbf-kernel" class="unnumbered">Comparsion of linear and RBF kernel</h2>
<p>In the model I used linear and RBF kernels SVM classifier.<br />
</p>
<table>
<thead>
<tr class="header">
<th align="left">Feature extractor</th>
<th align="left">Kernel</th>
<th align="left">Representation</th>
<th align="left">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left">43.0%</td>
</tr>
<tr class="even">
<td align="left">SIFT</td>
<td align="left">RBF</td>
<td align="left">Bag of words</td>
<td align="left">17.7%</td>
</tr>
<tr class="odd">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left">41.9%</td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">RBF</td>
<td align="left">Bag of words</td>
<td align="left">23.2%</td>
</tr>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.4%</td>
</tr>
<tr class="even">
<td align="left">SIFT</td>
<td align="left">RBF</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.2%</td>
</tr>
<tr class="odd">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.3%</td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">RBF</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.7%</td>
</tr>
</tbody>
</table>
<p>Table 2 shows the comparsion between RBF and linear kernels. For the RBF kernel I used <span class="math inline"><em>γ</em></span> in the ’auto’ mode which uses value <span class="math inline">$\frac{1}{number\_of\_features}$</span>. Radial kernel has much higher variance than linear kernel and SVM classifier is much more unstable than in case of linear kernel. One could see it for the Bag of words approach, when for dafault values of <span class="math inline"><em>γ</em></span> mode has <span class="math inline">23.3%</span> and <span class="math inline">18.7%</span> lower accuracy!</p>
<p>With use of Bag of words RBF kernel has similar accuracy to linear kernel, with the best accuracy among all models which is <span class="math inline">46.7%</span></p>
<h2 id="comparsion-of-bag-of-words-and-spatial-pyramid" class="unnumbered">Comparsion of Bag of Words and Spatial Pyramid</h2>
<p>In the model I used Bag of Words and Spatial Pyramid representation.</p>
<table>
<thead>
<tr class="header">
<th align="left">Feature extractor</th>
<th align="left">Kernel</th>
<th align="left">Representation</th>
<th align="left">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.4%</td>
</tr>
<tr class="even">
<td align="left">SIFT</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left">43.0%</td>
</tr>
<tr class="odd">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.3%</td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">Linear</td>
<td align="left">Bag of words</td>
<td align="left">41.9%</td>
</tr>
<tr class="odd">
<td align="left">SIFT</td>
<td align="left">RBF</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.2%</td>
</tr>
<tr class="even">
<td align="left">SIFT</td>
<td align="left">RBF</td>
<td align="left">Bag of words</td>
<td align="left">17.7%</td>
</tr>
<tr class="odd">
<td align="left">HOG</td>
<td align="left">RBF</td>
<td align="left">Spatial pyramid</td>
<td align="left">46.7%</td>
</tr>
<tr class="even">
<td align="left">HOG</td>
<td align="left">RBF</td>
<td align="left">Bag of words</td>
<td align="left">23.2%</td>
</tr>
</tbody>
</table>
<p>Table 3 shows that on average Bag of Words has on average <span class="math inline">2.4%</span> lower accuracy using linear kernel than Spatial Pyramid and <span class="math inline">26%</span> lower using RBF kernel. It is a significant difference and in many more complex task, Spatial Pyramid could outperform Bag of Words.</p>
<h1 id="future-works" class="unnumbered">Future works</h1>
<p>In the further development of the model one could use Cross Validation scheme to try multiple kernels, and <span class="math inline"><em>γ</em></span> values. Also more training points could be used during the training process.</p>
</body>
</html>
